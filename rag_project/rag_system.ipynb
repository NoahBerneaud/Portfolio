{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from haystack import Pipeline\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "from milvus_haystack import MilvusDocumentStore\n",
    "from milvus_haystack.milvus_embedding_retriever import MilvusEmbeddingRetriever\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('hf://datasets/AgentPublic/piaf/plain_text/train-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0fe2b",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897f233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'context', 'question', 'answers']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d76ef76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>id</th><th>title</th><th>context</th><th>question</th><th>answers</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;3835&quot;</td><td>&quot;3835&quot;</td><td>&quot;3835&quot;</td><td>&quot;3835&quot;</td><td>3835.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;p140295201616088&quot;</td><td>&quot;6 Heures de Shanghai 2017&quot;</td><td>&quot;2012 est sorti en 2012. Son th\u2026</td><td>&quot;A cause de qui Emanuele se voi\u2026</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;p140295460357824&quot;</td><td>&quot;\u00c9v\u00e9nement Azolla&quot;</td><td>&quot;\u00c9tienne B\u00e1thory, roi de Pologn\u2026</td><td>&quot;\u00e0 quelle ronde f\u00e9nix est sorti\u2026</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 6)\n",
       "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
       "\u2502 statistic  \u2506 id               \u2506 title            \u2506 context          \u2506 question         \u2506 answers \u2502\n",
       "\u2502 ---        \u2506 ---              \u2506 ---              \u2506 ---              \u2506 ---              \u2506 ---     \u2502\n",
       "\u2502 str        \u2506 str              \u2506 str              \u2506 str              \u2506 str              \u2506 f64     \u2502\n",
       "\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
       "\u2502 count      \u2506 3835             \u2506 3835             \u2506 3835             \u2506 3835             \u2506 3835.0  \u2502\n",
       "\u2502 null_count \u2506 0                \u2506 0                \u2506 0                \u2506 0                \u2506 0.0     \u2502\n",
       "\u2502 mean       \u2506 null             \u2506 null             \u2506 null             \u2506 null             \u2506 null    \u2502\n",
       "\u2502 std        \u2506 null             \u2506 null             \u2506 null             \u2506 null             \u2506 null    \u2502\n",
       "\u2502 min        \u2506 p140295201616088 \u2506 6 Heures de      \u2506 2012 est sorti   \u2506 A cause de qui   \u2506 null    \u2502\n",
       "\u2502            \u2506                  \u2506 Shanghai 2017    \u2506 en 2012. Son th\u2026 \u2506 Emanuele se voi\u2026 \u2506         \u2502\n",
       "\u2502 25%        \u2506 null             \u2506 null             \u2506 null             \u2506 null             \u2506 null    \u2502\n",
       "\u2502 50%        \u2506 null             \u2506 null             \u2506 null             \u2506 null             \u2506 null    \u2502\n",
       "\u2502 75%        \u2506 null             \u2506 null             \u2506 null             \u2506 null             \u2506 null    \u2502\n",
       "\u2502 max        \u2506 p140295460357824 \u2506 \u00c9v\u00e9nement Azolla \u2506 \u00c9tienne B\u00e1thory, \u2506 \u00e0 quelle ronde   \u2506 null    \u2502\n",
       "\u2502            \u2506                  \u2506                  \u2506 roi de Pologn\u2026   \u2506 f\u00e9nix est sorti\u2026 \u2506         \u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42203b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 5)\n",
      "\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
      "\u2502 id  \u2506 title \u2506 context \u2506 question \u2506 answers \u2502\n",
      "\u2502 --- \u2506 ---   \u2506 ---     \u2506 ---      \u2506 ---     \u2502\n",
      "\u2502 u32 \u2506 u32   \u2506 u32     \u2506 u32      \u2506 u32     \u2502\n",
      "\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n",
      "\u2502 0   \u2506 0     \u2506 0       \u2506 0        \u2506 0       \u2502\n",
      "\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
      "3835\n"
     ]
    }
   ],
   "source": [
    "# Indiquer le nombre de valeur nulle dans chaque colonne\n",
    "print(df.null_count())\n",
    "\n",
    "# Indiquer le nombre de lignes\n",
    "print(df.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3f90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 2500 rows\n",
    "df = df.head(2500)\n",
    "train_df, val_df, test_df = df.random_split([0.7, 0.15, 0.15], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43d4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "\n",
    "# Create document lists for each dataset split\n",
    "train_documents = [\n",
    "    Document(\n",
    "        content=row['context'],\n",
    "        meta={'id': row['id'], 'title': row['title']}\n",
    "    )\n",
    "    for row in train_df.to_dicts()\n",
    "]\n",
    "\n",
    "val_documents = [\n",
    "    Document(\n",
    "        content=row['context'],\n",
    "        meta={'id': row['id'], 'title': row['title']}\n",
    "    )\n",
    "    for row in val_df.to_dicts()\n",
    "]\n",
    "\n",
    "test_documents = [\n",
    "    Document(\n",
    "        content=row['context'],\n",
    "        meta={'id': row['id'], 'title': row['title']}\n",
    "    )\n",
    "    for row in test_df.to_dicts()\n",
    "]\n",
    "\n",
    "# Use training documents for indexing\n",
    "documents = train_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774824ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_list = [\n",
    "    \"intfloat/multilingual-e5-large-instruct\",\n",
    "    \"Lajavaness/bilingual-embedding-large\",\n",
    "    \"HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: intfloat/multilingual-e5-large-instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c425594ca946a7b19b323bd058e156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 2500 documents with model intfloat/multilingual-e5-large-instruct\n",
      "Model 2: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a55a1d5b1742ef8971bdaa8e84e14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 2500 documents with model Lajavaness/bilingual-embedding-large\n",
      "Model 3: HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061dfe34b7fa40e995d8e294548e7420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 2500 documents with model HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(embedding_model_list):\n",
    "    print(f\"Model {i+1}: {model}\")\n",
    "    embedder = SentenceTransformersDocumentEmbedder(model = model, trust_remote_code=True)\n",
    "    embedder.warm_up()\n",
    "\n",
    "    document_store = MilvusDocumentStore(\n",
    "        connection_args={\"uri\": \"./milvus.db\"},\n",
    "        drop_old=True,\n",
    "        collection_name=f\"piaf_{i+1}\"\n",
    "    )\n",
    "    indexing_pipeline = Pipeline()\n",
    "    indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "    indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store))\n",
    "    indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "    indexing_pipeline.run({\"documents\": documents})\n",
    "    print(f\"Indexed {len(documents)} documents with model {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b92027d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack import Pipeline\n",
    "\n",
    "# 1. DocumentStore en m\u00e9moire avec BM25\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935af896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: intfloat/multilingual-e5-large-instruct\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MilvusDocumentStore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m embedder = SentenceTransformersTextEmbedder(model=model, trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m, progress_bar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     11\u001b[39m embedder.warm_up()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m document_store = \u001b[43mMilvusDocumentStore\u001b[49m(\n\u001b[32m     14\u001b[39m     connection_args={\u001b[33m\"\u001b[39m\u001b[33muri\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m./milvus.db\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     15\u001b[39m     collection_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpiaf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m retrieval_pipeline = Pipeline()\n\u001b[32m     19\u001b[39m retrieval_pipeline.add_component(\u001b[33m\"\u001b[39m\u001b[33membedder\u001b[39m\u001b[33m\"\u001b[39m, embedder)\n",
      "\u001b[31mNameError\u001b[39m: name 'MilvusDocumentStore' is not defined"
     ]
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.evaluators import DocumentMAPEvaluator, DocumentMRREvaluator, DocumentRecallEvaluator, DocumentNDCGEvaluator\n",
    "from haystack import Document, Pipeline\n",
    "\n",
    "\n",
    "for i, model in enumerate(embedding_model_list):\n",
    "    grounds_truth = []\n",
    "    retrieval_results_list = []\n",
    "    print(f\"Model {i+1}: {model}\")\n",
    "    embedder = SentenceTransformersTextEmbedder(model=model, trust_remote_code=True, progress_bar=False)\n",
    "    embedder.warm_up()\n",
    "\n",
    "    document_store = MilvusDocumentStore(\n",
    "        connection_args={\"uri\": \"./milvus.db\"},\n",
    "        collection_name=f\"piaf_{i+1}\"\n",
    "    )\n",
    "\n",
    "    retrieval_pipeline = Pipeline()\n",
    "    retrieval_pipeline.add_component(\"embedder\", embedder)\n",
    "    retrieval_pipeline.add_component(\"retriever\", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "    retrieval_pipeline.connect(\"embedder\", \"retriever\")\n",
    "\n",
    "    for row in test_df.to_dicts():\n",
    "        retrieval_results = retrieval_pipeline.run({\"embedder\": {\"text\": row[\"question\"]}})\n",
    "        grounds_truth.append([Document(\n",
    "            content=row[\"context\"],\n",
    "            meta={\n",
    "                \"id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "            }\n",
    "        )])\n",
    "        retrieval_result = retrieval_results[\"retriever\"][\"documents\"]\n",
    "        retrieval_results_list.append(retrieval_result)\n",
    "    evaluator = Pipeline()\n",
    "    mrr_evaluator = DocumentMRREvaluator()\n",
    "    map_evaluator = DocumentMAPEvaluator()\n",
    "    recall = DocumentRecallEvaluator()\n",
    "    ndcg = DocumentNDCGEvaluator()\n",
    "    evaluator.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "    evaluator.add_component(\"map_evaluator\", map_evaluator)\n",
    "    evaluator.add_component(\"recall_evaluator\", recall)\n",
    "    evaluator.add_component(\"ndcg_evaluator\", ndcg)\n",
    "    score = evaluator.run({\n",
    "        \"mrr_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "        \"map_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "        \"recall_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "        \"ndcg_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth}\n",
    "    }\n",
    "    )\n",
    "    print(f\"Score for model {model}: \")\n",
    "    print(f\"MRR: {score['mrr_evaluator']['score']}\")\n",
    "    print(f\"MAP: {score['map_evaluator']['score']}\")\n",
    "    print(f\"Recall: {score['recall_evaluator']['score']}\")\n",
    "    print(f\"NDCG: {score['ndcg_evaluator']['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5366c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "retrieval_pipeline = Pipeline()\n",
    "retrieval_pipeline.add_component(\"retriever\", retriever)\n",
    "\n",
    "\n",
    "grounds_truth = []\n",
    "retrieval_results_list = []\n",
    "\n",
    "for row in test_df.to_dicts():\n",
    "    retrieval_results = retrieval_pipeline.run({\"retriever\": {\"query\": row[\"question\"]}})\n",
    "    grounds_truth.append([Document(\n",
    "        content=row[\"context\"],\n",
    "        meta={\n",
    "            \"id\": row[\"id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "        }\n",
    "    )])\n",
    "    retrieval_result = retrieval_results[\"retriever\"][\"documents\"]\n",
    "    retrieval_results_list.append(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Pipeline()\n",
    "mrr_evaluator = DocumentMRREvaluator()\n",
    "map_evaluator = DocumentMAPEvaluator()\n",
    "recall = DocumentRecallEvaluator()\n",
    "ndcg = DocumentNDCGEvaluator()\n",
    "evaluator.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "evaluator.add_component(\"map_evaluator\", map_evaluator)\n",
    "evaluator.add_component(\"recall_evaluator\", recall)\n",
    "evaluator.add_component(\"ndcg_evaluator\", ndcg)\n",
    "score = evaluator.run({\n",
    "    \"mrr_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "    \"map_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "    \"recall_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "    \"ndcg_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth}\n",
    "}\n",
    ")\n",
    "print(f\"Score for model {model}: \")\n",
    "print(f\"MRR: {score['mrr_evaluator']['score']}\")\n",
    "print(f\"MAP: {score['map_evaluator']['score']}\")\n",
    "print(f\"Recall: {score['recall_evaluator']['score']}\")\n",
    "print(f\"NDCG: {score['ndcg_evaluator']['score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
