{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ebb6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from haystack import Pipeline\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "from milvus_haystack import MilvusDocumentStore\n",
    "from milvus_haystack.milvus_embedding_retriever import MilvusEmbeddingRetriever\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a402f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('hf://datasets/AgentPublic/piaf/plain_text/train-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8db3fba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Combien de personnes travaillent au ministère des sports']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0][\"question\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0fe2b",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "897f233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'context', 'question', 'answers']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d76ef76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>id</th><th>title</th><th>context</th><th>question</th><th>answers</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;3835&quot;</td><td>&quot;3835&quot;</td><td>&quot;3835&quot;</td><td>&quot;3835&quot;</td><td>3835.0</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;p140295201616088&quot;</td><td>&quot;6 Heures de Shanghai 2017&quot;</td><td>&quot;2012 est sorti en 2012. Son th…</td><td>&quot;A cause de qui Emanuele se voi…</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;p140295460357824&quot;</td><td>&quot;Événement Azolla&quot;</td><td>&quot;Étienne Báthory, roi de Pologn…</td><td>&quot;à quelle ronde fénix est sorti…</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 6)\n",
       "┌────────────┬──────────────────┬──────────────────┬──────────────────┬──────────────────┬─────────┐\n",
       "│ statistic  ┆ id               ┆ title            ┆ context          ┆ question         ┆ answers │\n",
       "│ ---        ┆ ---              ┆ ---              ┆ ---              ┆ ---              ┆ ---     │\n",
       "│ str        ┆ str              ┆ str              ┆ str              ┆ str              ┆ f64     │\n",
       "╞════════════╪══════════════════╪══════════════════╪══════════════════╪══════════════════╪═════════╡\n",
       "│ count      ┆ 3835             ┆ 3835             ┆ 3835             ┆ 3835             ┆ 3835.0  │\n",
       "│ null_count ┆ 0                ┆ 0                ┆ 0                ┆ 0                ┆ 0.0     │\n",
       "│ mean       ┆ null             ┆ null             ┆ null             ┆ null             ┆ null    │\n",
       "│ std        ┆ null             ┆ null             ┆ null             ┆ null             ┆ null    │\n",
       "│ min        ┆ p140295201616088 ┆ 6 Heures de      ┆ 2012 est sorti   ┆ A cause de qui   ┆ null    │\n",
       "│            ┆                  ┆ Shanghai 2017    ┆ en 2012. Son th… ┆ Emanuele se voi… ┆         │\n",
       "│ 25%        ┆ null             ┆ null             ┆ null             ┆ null             ┆ null    │\n",
       "│ 50%        ┆ null             ┆ null             ┆ null             ┆ null             ┆ null    │\n",
       "│ 75%        ┆ null             ┆ null             ┆ null             ┆ null             ┆ null    │\n",
       "│ max        ┆ p140295460357824 ┆ Événement Azolla ┆ Étienne Báthory, ┆ à quelle ronde   ┆ null    │\n",
       "│            ┆                  ┆                  ┆ roi de Pologn…   ┆ fénix est sorti… ┆         │\n",
       "└────────────┴──────────────────┴──────────────────┴──────────────────┴──────────────────┴─────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42203b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 5)\n",
      "┌─────┬───────┬─────────┬──────────┬─────────┐\n",
      "│ id  ┆ title ┆ context ┆ question ┆ answers │\n",
      "│ --- ┆ ---   ┆ ---     ┆ ---      ┆ ---     │\n",
      "│ u32 ┆ u32   ┆ u32     ┆ u32      ┆ u32     │\n",
      "╞═════╪═══════╪═════════╪══════════╪═════════╡\n",
      "│ 0   ┆ 0     ┆ 0       ┆ 0        ┆ 0       │\n",
      "└─────┴───────┴─────────┴──────────┴─────────┘\n",
      "3835\n"
     ]
    }
   ],
   "source": [
    "# Indiquer le nombre de valeur nulle dans chaque colonne\n",
    "print(df.null_count())\n",
    "\n",
    "# Indiquer le nombre de lignes\n",
    "print(df.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e3f90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 2500 rows\n",
    "df = df.head(2500)\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df_shuffled = df.sample(fraction=1.0, with_replacement=False, seed=42)\n",
    "\n",
    "# Calculate split indices\n",
    "n = df_shuffled.height\n",
    "train_end = int(n * 0.7)\n",
    "val_end = train_end + int(n * 0.15)\n",
    "\n",
    "# Split the dataframe\n",
    "train_df = df_shuffled[:train_end]\n",
    "val_df = df_shuffled[train_end:val_end]\n",
    "test_df = df_shuffled[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e43d4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "\n",
    "# Create document lists for each dataset split\n",
    "train_documents = [\n",
    "    Document(\n",
    "        content=row['context'],\n",
    "        meta={'id': row['id'], 'title': row['title']}\n",
    "    )\n",
    "    for row in train_df.to_dicts()\n",
    "]\n",
    "\n",
    "val_documents = [\n",
    "    Document(\n",
    "        content=row['context'],\n",
    "        meta={'id': row['id'], 'title': row['title']}\n",
    "    )\n",
    "    for row in val_df.to_dicts()\n",
    "]\n",
    "\n",
    "test_documents = [\n",
    "    Document(\n",
    "        content=row['context'],\n",
    "        meta={'id': row['id'], 'title': row['title']}\n",
    "    )\n",
    "    for row in test_df.to_dicts()\n",
    "]\n",
    "\n",
    "# Use training documents for indexing\n",
    "documents = test_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774824ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_list = [\n",
    "    \"intfloat/multilingual-e5-large-instruct\",\n",
    "    \"Lajavaness/bilingual-embedding-large\",\n",
    "    \"HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f7abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: intfloat/multilingual-e5-large-instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60028e33df3349fe8379f1801620c6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 375 documents with model intfloat/multilingual-e5-large-instruct\n",
      "Model 2: Lajavaness/bilingual-embedding-large\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362ffe01fad24457aa037419c16004a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 375 documents with model Lajavaness/bilingual-embedding-large\n",
      "Model 3: HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d34d58390745ebbd013cb9f03eb9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 375 documents with model HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\n",
      "Model 4: Qwen/Qwen3-Embedding-8B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d9bb02d5c64e76b2ae9577d2b3fb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cc5f08c3fd41b7a711236efcd4365e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5c4f92004048e48401fb0128843304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d3a2853ccc4ac1acfcbce55d6504ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba894140c65646c69e95ba5eb8e5f0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/30.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ff1c7dfb0a4c07821cded941858d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e99e3877c6246a2aa1a3e411be35568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf858e5c54d4273a8441872835b54a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958724c5795c4468b42adb882cf35bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0a74cdaf3149b6821cee206e019ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c17426d79f4bfba2c62b600bd9a745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799aea1a0c8e4667ae44920f68f01bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb07c9b7e6842e49613fd55ec4d79bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3822b2f26708475f96d96212963ea053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabb2653cb4a467cad019e3d52a932ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a137e74f348c481ca19d3457654ac537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec0f7f7287c499c88d8863d04981cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PipelineRuntimeError",
     "evalue": "The following component failed to run:\nComponent name: 'embedder'\nComponent type: 'SentenceTransformersDocumentEmbedder'\nError: MPS backend out of memory (MPS allocated: 35.95 GB, other allocations: 2.12 MB, max allowed: 36.27 GB). Tried to allocate 333.06 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/haystack/core/pipeline/pipeline.py:60\u001b[39m, in \u001b[36mPipeline._run_component\u001b[39m\u001b[34m(component_name, component, inputs, component_visits, parent_span)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     component_output = \u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/haystack/components/embedders/sentence_transformers_document_embedder.py:244\u001b[39m, in \u001b[36mSentenceTransformersDocumentEmbedder.run\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m    242\u001b[39m     texts_to_embed.append(text_to_embed)\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(documents, embeddings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/haystack/components/embedders/backends/sentence_transformers_backend.py:85\u001b[39m, in \u001b[36m_SentenceTransformersEmbeddingBackend.embed\u001b[39m\u001b[34m(self, data, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: List[\u001b[38;5;28mstr\u001b[39m], **kwargs) -> List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.tolist()\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:685\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:758\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m    757\u001b[39m     module_kwargs = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:442\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    436\u001b[39m trans_features = {\n\u001b[32m    437\u001b[39m     key: value\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    440\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:463\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    461\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:284\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py:235\u001b[39m, in \u001b[36mQwen3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m         attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# diff with Llama\u001b[39;49;00m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/transformers/integrations/sdpa_attention.py:54\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m     is_causal = is_causal.item()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 35.95 GB, other allocations: 2.12 MB, max allowed: 36.27 GB). Tried to allocate 333.06 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPipelineRuntimeError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m indexing_pipeline.add_component(\u001b[33m\"\u001b[39m\u001b[33mwriter\u001b[39m\u001b[33m\"\u001b[39m, DocumentWriter(document_store))\n\u001b[32m     14\u001b[39m indexing_pipeline.connect(\u001b[33m\"\u001b[39m\u001b[33membedder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwriter\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mindexing_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndexed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents with model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/haystack/core/pipeline/pipeline.py:235\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, data, include_outputs_from)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# We need to add missing defaults using default values from input sockets because the run signature\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# might not provide these defaults for components with inputs defined dynamically upon component\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# initialization\u001b[39;00m\n\u001b[32m    233\u001b[39m component_inputs = \u001b[38;5;28mself\u001b[39m._add_missing_input_defaults(component_inputs, component[\u001b[33m\"\u001b[39m\u001b[33minput_sockets\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m component_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_component\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponent_visits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomponent_visits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparent_span\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Updates global input state with component outputs and returns outputs that should go to\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# pipeline outputs.\u001b[39;00m\n\u001b[32m    246\u001b[39m component_pipeline_outputs = \u001b[38;5;28mself\u001b[39m._write_component_outputs(\n\u001b[32m    247\u001b[39m     component_name=component_name,\n\u001b[32m    248\u001b[39m     component_outputs=component_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m     include_outputs_from=include_outputs_from,\n\u001b[32m    252\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/portfolio/rag_project/.venv/lib/python3.11/site-packages/haystack/core/pipeline/pipeline.py:62\u001b[39m, in \u001b[36mPipeline._run_component\u001b[39m\u001b[34m(component_name, component, inputs, component_visits, parent_span)\u001b[39m\n\u001b[32m     60\u001b[39m     component_output = instance.run(**inputs)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineRuntimeError.from_exception(component_name, instance.\u001b[34m__class__\u001b[39m, error) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m\n\u001b[32m     63\u001b[39m component_visits[component_name] += \u001b[32m1\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(component_output, Mapping):\n",
      "\u001b[31mPipelineRuntimeError\u001b[39m: The following component failed to run:\nComponent name: 'embedder'\nComponent type: 'SentenceTransformersDocumentEmbedder'\nError: MPS backend out of memory (MPS allocated: 35.95 GB, other allocations: 2.12 MB, max allowed: 36.27 GB). Tried to allocate 333.06 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(embedding_model_list):\n",
    "    print(f\"Model {i+1}: {model}\")\n",
    "    embedder = SentenceTransformersDocumentEmbedder(model = model, trust_remote_code=True)\n",
    "    embedder.warm_up()\n",
    "\n",
    "    document_store = MilvusDocumentStore(\n",
    "        connection_args={\"uri\": \"./milvus.db\"},\n",
    "        drop_old=True,\n",
    "        collection_name=f\"piaf_{i+1}\"\n",
    "    )\n",
    "    indexing_pipeline = Pipeline()\n",
    "    indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "    indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store))\n",
    "    indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "    indexing_pipeline.run({\"documents\": documents})\n",
    "    print(f\"Indexed {len(documents)} documents with model {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935af896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: intfloat/multilingual-e5-large-instruct\n",
      "Score for model intfloat/multilingual-e5-large-instruct: \n",
      "MRR: 0.6666666666666666\n",
      "MAP: 0.6666666666666666\n",
      "Recall: 0.6666666666666666\n",
      "NDCG: 0.0\n",
      "Model 2: Lajavaness/bilingual-embedding-large\n",
      "Score for model Lajavaness/bilingual-embedding-large: \n",
      "MRR: 0.6693333333333333\n",
      "MAP: 0.6693333333333333\n",
      "Recall: 0.6693333333333333\n",
      "NDCG: 0.0\n",
      "Model 3: HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1\n",
      "Score for model HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1: \n",
      "MRR: 0.648\n",
      "MAP: 0.648\n",
      "Recall: 0.648\n",
      "NDCG: 0.0\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.evaluators import DocumentMAPEvaluator, DocumentMRREvaluator, DocumentRecallEvaluator, DocumentNDCGEvaluator\n",
    "from haystack import Document, Pipeline\n",
    "\n",
    "\n",
    "for i, model in enumerate(embedding_model_list):\n",
    "    grounds_truth = []\n",
    "    retrieval_results_list = []\n",
    "    print(f\"Model {i+1}: {model}\")\n",
    "    embedder = SentenceTransformersTextEmbedder(model=model, trust_remote_code=True, progress_bar=False)\n",
    "    embedder.warm_up()\n",
    "\n",
    "    document_store = MilvusDocumentStore(\n",
    "        connection_args={\"uri\": \"./milvus.db\"},\n",
    "        collection_name=f\"piaf_{i+1}\"\n",
    "    )\n",
    "\n",
    "    retrieval_pipeline = Pipeline()\n",
    "    retrieval_pipeline.add_component(\"embedder\", embedder)\n",
    "    retrieval_pipeline.add_component(\"retriever\", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "    retrieval_pipeline.connect(\"embedder\", \"retriever\")\n",
    "\n",
    "    for row in test_df.to_dicts():\n",
    "        retrieval_results = retrieval_pipeline.run({\"embedder\": {\"text\": row[\"question\"]}})\n",
    "        grounds_truth.append([Document(\n",
    "            content=row[\"context\"],\n",
    "            meta={\n",
    "                \"id\": row[\"id\"],\n",
    "                \"title\": row[\"title\"],\n",
    "            }\n",
    "        )])\n",
    "        retrieval_result = retrieval_results[\"retriever\"][\"documents\"]\n",
    "        retrieval_results_list.append(retrieval_result)\n",
    "    evaluator = Pipeline()\n",
    "    mrr_evaluator = DocumentMRREvaluator()\n",
    "    map_evaluator = DocumentMAPEvaluator()\n",
    "    recall = DocumentRecallEvaluator()\n",
    "    ndcg = DocumentNDCGEvaluator()\n",
    "    evaluator.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "    evaluator.add_component(\"map_evaluator\", map_evaluator)\n",
    "    evaluator.add_component(\"recall_evaluator\", recall)\n",
    "    evaluator.add_component(\"ndcg_evaluator\", ndcg)\n",
    "    score = evaluator.run({\n",
    "        \"mrr_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "        \"map_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "        \"recall_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "        \"ndcg_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth}\n",
    "    }\n",
    "    )\n",
    "    print(f\"Score for model {model}: \")\n",
    "    print(f\"MRR: {score['mrr_evaluator']['score']}\")\n",
    "    print(f\"MAP: {score['map_evaluator']['score']}\")\n",
    "    print(f\"Recall: {score['recall_evaluator']['score']}\")\n",
    "    print(f\"NDCG: {score['ndcg_evaluator']['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5366c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack import Pipeline\n",
    "\n",
    "# 1. DocumentStore en mémoire avec BM25\n",
    "document_store = InMemoryDocumentStore()\n",
    "document_store.write_documents(documents)\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "retrieval_pipeline = Pipeline()\n",
    "retrieval_pipeline.add_component(\"retriever\", retriever)\n",
    "\n",
    "\n",
    "grounds_truth = []\n",
    "retrieval_results_list = []\n",
    "\n",
    "for row in test_df.to_dicts():\n",
    "    retrieval_results = retrieval_pipeline.run({\"retriever\": {\"query\": row[\"question\"]}})\n",
    "    grounds_truth.append([Document(\n",
    "        content=row[\"context\"],\n",
    "        meta={\n",
    "            \"id\": row[\"id\"],\n",
    "            \"title\": row[\"title\"],\n",
    "        }\n",
    "    )])\n",
    "    retrieval_result = retrieval_results[\"retriever\"][\"documents\"]\n",
    "    retrieval_results_list.append(retrieval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bea8ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for model HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1: \n",
      "MRR: 0.6371111111111107\n",
      "MAP: 0.6576162257495586\n",
      "Recall: 0.7306666666666667\n",
      "NDCG: 0.39933996689679263\n"
     ]
    }
   ],
   "source": [
    "evaluator = Pipeline()\n",
    "mrr_evaluator = DocumentMRREvaluator()\n",
    "map_evaluator = DocumentMAPEvaluator()\n",
    "recall = DocumentRecallEvaluator()\n",
    "ndcg = DocumentNDCGEvaluator()\n",
    "evaluator.add_component(\"mrr_evaluator\", mrr_evaluator)\n",
    "evaluator.add_component(\"map_evaluator\", map_evaluator)\n",
    "evaluator.add_component(\"recall_evaluator\", recall)\n",
    "evaluator.add_component(\"ndcg_evaluator\", ndcg)\n",
    "score = evaluator.run({\n",
    "    \"mrr_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "    \"map_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "    \"recall_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth},\n",
    "    \"ndcg_evaluator\": {\"retrieved_documents\": retrieval_results_list, \"ground_truth_documents\": grounds_truth}\n",
    "}\n",
    ")\n",
    "print(f\"Score for model {model}: \")\n",
    "print(f\"MRR: {score['mrr_evaluator']['score']}\")\n",
    "print(f\"MAP: {score['map_evaluator']['score']}\")\n",
    "print(f\"Recall: {score['recall_evaluator']['score']}\")\n",
    "print(f\"NDCG: {score['ndcg_evaluator']['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c4eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"piaf_results\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments\n",
    ")\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from datasets import Dataset\n",
    "\n",
    "# 1. Modèle de base\n",
    "base_model = \"intfloat/multilingual-e5-large-instruct\"\n",
    "model = SentenceTransformer(base_model)\n",
    "\n",
    "# 2. Préparation des données\n",
    "train_examples = [\n",
    "    {\"anchor\": row[\"question\"], \"positive\": row[\"context\"]}\n",
    "    for row in train_df.to_dicts()\n",
    "]\n",
    "train_dataset = Dataset.from_list(train_examples)\n",
    "\n",
    "val_queries = {f\"q{i}\": row[\"question\"] for i, row in enumerate(val_df.to_dicts())}\n",
    "val_corpus  = {f\"d{i}\": row[\"context\"]  for i, row in enumerate(val_df.to_dicts())}\n",
    "val_rel     = {qid: {did: 1} for qid, did in zip(val_queries, val_corpus)}\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(\n",
    "    val_queries, val_corpus, val_rel, name=\"piaf-validation\"\n",
    ")\n",
    "\n",
    "# 3. Loss\n",
    "train_loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# 4. Hyper-paramètres adaptés à MPS\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=output_path,                # dossier de sortie\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.1,\n",
    "    # Désactivation explicite de toute mixed precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    ")\n",
    "\n",
    "# 5. Création du Trainer et lancement\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    evaluator=evaluator,\n",
    "    loss=train_loss\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# 6. Sauvegarde\n",
    "model.save_pretrained(output_path)\n",
    "print(f\"✓ Modèle entraîné et sauvegardé dans : {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d7f8a",
   "metadata": {},
   "source": [
    "## Indexing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "badaf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_name = \"intfloat/multilingual-e5-large-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107158a1ee1843a5b0e770a430af7d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb3a8c5932644118d9ecd051cb892ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2dd97e32b3741eca6dcd6da9abeb6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 375 documents with model SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
      "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformersDocumentEmbedder(model = final_model_name, trust_remote_code=True)\n",
    "embedder.warm_up()\n",
    "\n",
    "document_store = MilvusDocumentStore(\n",
    "    connection_args={\"uri\": \"./milvus.db\"},\n",
    "    drop_old=True,\n",
    "    collection_name=\"piaf_final_model\"\n",
    ")\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"embedder\", embedder)\n",
    "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store))\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "indexing_pipeline.run({\"documents\": train_documents})\n",
    "indexing_pipeline.run({\"documents\": val_documents})\n",
    "indexing_pipeline.run({\"documents\": test_documents})\n",
    "print(f\"Indexed {len(documents)} documents with model {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07a0ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.count_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fbe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
